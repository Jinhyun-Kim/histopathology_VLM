{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "execute_cell"
    ]
   },
   "outputs": [],
   "source": [
    "data_root_dir = \"/nfs_share/students/jinhyun/TCGA/BRCA\"\n",
    "result_file_path = \"results/InternVL2_5-78B-MPO_randompatch224_20_rep1.xlsx\"\n",
    "result_file_path = \"results/InternVL2_5-78B-MPO_randompatch224_20_rep2.xlsx\"\n",
    "result_file_path = \"results/InternVL2_5-78B-MPO_randompatch448_20.xlsx\"\n",
    "result_file_path = \"results/InternVL2_5-78B-MPO_randompatch224_20_with_explain.xlsx\"\n",
    "result_file_path = \"results/InternVL2_5-78B-MPO_multiscale_patch448_20.xlsx\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_prognosis(value):\n",
    "    \"\"\"Maps prognosis values into year-based categories.\"\"\"\n",
    "    trunc_val = 7\n",
    "    if value <= trunc_val-1:\n",
    "        return value\n",
    "    else:\n",
    "        return trunc_val\n",
    "\n",
    "def extract_numeric_part_and_to_year(label):\n",
    "    \"\"\" Extract unique labels and sort them based on the number preceding '-'\"\"\"\n",
    "    return round(float(label.split('-')[0])/373) + 1 if label.split('-')[0].isdigit() else np.nan\n",
    "\n",
    "def prepare_df(result_file_path):\n",
    "    df = pd.read_excel(result_file_path)\n",
    "    df['Predicted Prognosis'] = df['Predicted Prognosis'].astype(str).str.split('\\n').str[0]\n",
    "    df_filtered = df[df['Predicted Prognosis'] != \"Not supplied\"].copy()\n",
    "    print(f\"Found {len(df_filtered)}/{len(df)} predictions from VLM\")\n",
    "\n",
    "    df_filtered['Actual Year'] = df_filtered['Actual Prognosis'].apply(extract_numeric_part_and_to_year)\n",
    "    df_filtered['Predicted Year'] = df_filtered['Predicted Prognosis'].apply(extract_numeric_part_and_to_year)\n",
    "    \n",
    "    df_filtered['Actual Truncated'] = df_filtered['Actual Year'].apply(categorize_prognosis)\n",
    "    df_filtered['Predicted Truncated'] = df_filtered['Predicted Year'].apply(categorize_prognosis)\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "def evaluate_model(df, tolerance_n = 1):\n",
    "    target_value_name = \"Truncated\"\n",
    "    # target_value_name = \"Year\"\n",
    "\n",
    "    labels = df[[\"Actual Prognosis\", 'Actual Year', 'Actual Truncated']].drop_duplicates().sort_values(by = ['Actual Year'])[f\"Actual {target_value_name}\"].drop_duplicates()\n",
    "    y_true = df[f\"Actual {target_value_name}\"]\n",
    "    y_pred = df[f\"Predicted {target_value_name}\"]\n",
    "    # y_true = df[\"Actual Prognosis\"]\n",
    "    # y_pred = df[\"Predicted Prognosis\"]\n",
    "\n",
    "    # Compute accuracy and F1-score\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Weighted to consider class imbalance\n",
    "\n",
    "    # Compute Top-N Accuracy\n",
    "    tolerance_n_correct = np.abs(y_pred - y_true) <= tolerance_n  # 373 days per year threshold\n",
    "    tolerance_n_accuracy = np.mean(tolerance_n_correct)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Tolerance-{tolerance_n} accuracy: {tolerance_n_accuracy}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    print(cm)\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.yticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_df(result_file_path)\n",
    "\n",
    "# print(df[[\"Actual Truncated\"]].value_counts())\n",
    "print(df[[\"Actual Prognosis\", \"Actual Year\", \"Actual Truncated\"]].drop_duplicates())\n",
    "print(df[[\"Predicted Prognosis\", \"Predicted Year\", \"Predicted Truncated\"]].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
